# -*- coding: utf-8 -*-
"""tokenize.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lw4NiU_3zwjoEeRWHhhLHbB9KM_vSXP6
"""

import re

def tokenize_statement(statement):

    tokens = []

    keywords = r"\b(if|else|while|for|return|def|class|import|print)\b"
    identifiers = r"\b[a-zA-Z_][a-zA-Z0-9_]*\b"
    operators = r"(\+|-|\*|/|=|==|!=|>|<|>=|<=|%|\*\*)"
    int_literals = r"\b\d+\b"
    float_literals = r"\b\d+\.\d+\b"
    string_literals = r"\"[^\"]*\"|\'[^\']*\'"
    delimiters = r"(\(|\)|\[|\]|\{|\}|,|;)"

    pattern = "|".join([keywords, identifiers, operators, int_literals, float_literals, string_literals, delimiters])

    for match in re.finditer(pattern, statement):
        token = match.group(0)
        if re.match(keywords, token):
            token_type = "Keyword"
        elif re.match(identifiers, token):
            token_type = "Identifier"
        elif re.match(operators, token):
            token_type = "Operator"
        elif re.match(int_literals, token):
            token_type = "Integer Literal"
        elif re.match(float_literals, token):
            token_type = "Float Literal"
        elif re.match(string_literals, token):
            token_type = "String Literal"
        elif re.match(delimiters, token):
            token_type = "Delimiter"
        else:
            token_type = "Unknown"

        tokens.append((token, token_type))

    return tokens


if __name__ == "__main__":
    statement = input("Enter a statement: ")
    tokenized_output = tokenize_statement(statement)

    print("Tokenized Output:")
    for token, token_type in tokenized_output:
      print(f"{token} : {token_type}")